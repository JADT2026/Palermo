---
pagetitle: "12:10 / 13:20 - Solicited 1 - B"
---


<br>


# Sustainable Artificial Intelligence in Finance {#buttons .tabset .tabset-fade .tabset-pills}

<br>

### Organizer: Paola Cerchiello
### Chair: TBA

<br>

## RGB: a unified approach for safe and trustworthy AI
***
#### *Golnoosh Babaei, Paolo Giudici and Emanuela Raffinetti*

<br>

**Abstract:** The growth of Artificial Intelligence applications requires to develop risk management models that can balance opportunities with risks. In this paper, we con- tribute to the recently proposed S.A.F.E. risk management model, that can measure the Security, Accuracy, Fairness and Explainability of any Artificial Intelligence ap- plication. Our proposal intends to contribute with a unified approach which shares the same theoretical framework and allows to overcome one of the main drawbacks of the existing methodologies, that is the high computational effort. The final result consists in the integration of all the metrics for the evaluation of the Security, Accuracy, Fairness and Explainability principles into an agnostic score that provides an evaluation of the safety degree of any AI application.

Click [here]() to view the abstract.

## Informative set for fitting parameters of a piecewise density function
***
#### *Gloria Polinesi, Francesca Mariani and Maria Cristina Recchioni*

<br>

**Abstract:** Adaptive density estimation techniques enable construction of mixtures of return distributions useful as direct approximations. Indeed, the crucial element of the proposed approach is a comprehensive dataset -the informative set- derived from an adaptive clustering process, which characterizes the tail distributions of financial series. By utilizing this set it becomes easier to define the empirical distribution function, beginning with the log-normal mixture. We show the potential of the method through an example involving the observed prices of the volatility index (VIX). The effectiveness of the model is assessed based on its ability to accurately describe observed behavior of the sample data.

Click [here]() to view the abstract.

## Feature Dependence and Prediction Explanations in P2P Lending
***
#### *Paolo Pagnottoni and Thanh Thuy Do*

<br>

**Abstract:** Complex Machine Learning (ML) models used to support decision- making in peer-to-peer (P2P) lending often lack clear, accurate and interpretable explanations. While the game-theoretic concept of Shapley values and its computationally efficient variant Kernel SHAP may be employed to this aim, similarly to other existing methods, the latter makes the assumption that the features are inde- pendent. The assumption of uncorrelated features in credit risk management is fairly restrictive and, thus, prediction explanations coming from correlated features might result in highly misleading Shapley values, even when considering simple models. We therefore propose an evaluation of different dependent-feature estimation meth- ods of Kernel SHAP for classification purposes in credit risk management. We show that dependent-feature estimation of Shapley values can improve the understanding of true prediction explanations, their robustness, and is essential for better identifying the most relevant variables to default predictions coming from black-box ML models.

Click [here]() to view the abstract.